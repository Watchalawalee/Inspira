import scrapy
import re
import json
import datetime
import os
from scrapy_project.category.predictor import predict_category
import dateparser
import html

class AllThaiEventSpider(scrapy.Spider):
    name = "allthaievent_spider_upcoming"
    allowed_domains = ["allthaievent.com"]
    start_urls = ["https://www.allthaievent.com/monthlyevents/2025-03-01/"]

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.past_event_count = 0  # ‚úÖ ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô past event

    def parse(self, response):
        """ ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏≠‡∏µ‡πÄ‡∏ß‡πâ‡∏ô‡∏ó‡πå‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏£‡∏ß‡∏° ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏µ‡πÄ‡∏ß‡πâ‡∏ô‡∏ó‡πå """
        event_count = 0
        for event in response.css("div.thumbnail-xs"):
            relative_link = event.css("a::attr(href)").get()
            full_link = response.urljoin(relative_link)
            title = event.css("strong::text").get()

            if full_link and title:
                event_count += 1
                self.log(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å: {title}")
                yield response.follow(full_link, self.parse_event, meta={"title": title.strip()})

        if event_count == 0:
            self.log(f"üõë ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏µ‡πÄ‡∏ß‡πâ‡∏ô‡∏ó‡πå‡πÉ‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå: {response.url} ‚Äî ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
            return

        # ‚úÖ ‡πÅ‡∏¢‡∏Å‡∏õ‡∏µ‡πÅ‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏à‡∏≤‡∏Å URL ‡πÄ‡∏ä‡πà‡∏ô: 2025-03-01
        current_date_str = response.url.rstrip("/").split("/")[-1]  # 2025-03-01
        year, month, day = current_date_str.split("-")
        year = int(year)
        month = int(month)

        # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
        month += 1
        if month > 12:
            month = 1
            year += 1

        # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á URL ‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
        next_month_str = f"{year}-{month:02d}-01"
        next_url = f"https://www.allthaievent.com/monthlyevents/{next_month_str}/"

        self.log(f"‚û°Ô∏è ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ: {next_url}")
        yield scrapy.Request(next_url, callback=self.parse)

    def parse_event(self, response):
        """ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏≠‡∏µ‡πÄ‡∏ß‡πâ‡∏ô‡∏ó‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏±‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏ã‡∏ü‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏° `title` """
        title = response.meta.get("title", "No title")

        # ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (Description)
        description = self.extract_description(response)

        # ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà, ‡πÄ‡∏ß‡∏•‡∏≤, ‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà (‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏µ‡∏™‡πâ‡∏°)
        date_info = response.css("span[style*='#ff6600']::text").getall()
        start_date, end_date, event_slot_time, location = self.extract_event_details(date_info)

        # ‚úÖ ‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø)
        provinces = [
            "‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà", "‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ", "‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå", "‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£", "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô", "‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ", "‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤", "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ",
            "‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó", "‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥", "‡∏ä‡∏∏‡∏°‡∏û‡∏£", "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢", "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà", "‡∏ï‡∏£‡∏±‡∏á", "‡∏ï‡∏£‡∏≤‡∏î", "‡∏ï‡∏≤‡∏Å", "‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å",
            "‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°", "‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°", "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤", "‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä", "‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå", "‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ", "‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™",
            "‡∏ô‡πà‡∏≤‡∏ô", "‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨", "‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå", "‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ", "‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå", "‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ", "‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ", "‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤",
            "‡∏û‡∏±‡∏á‡∏á‡∏≤", "‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á", "‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£", "‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å", "‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ", "‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå", "‡πÅ‡∏û‡∏£‡πà", "‡∏û‡∏∞‡πÄ‡∏¢‡∏≤", "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï",
            "‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°", "‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£", "‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô", "‡∏¢‡πÇ‡∏™‡∏ò‡∏£", "‡∏¢‡∏∞‡∏•‡∏≤", "‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î", "‡∏£‡∏∞‡∏ô‡∏≠‡∏á", "‡∏£‡∏∞‡∏¢‡∏≠‡∏á", "‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ",
            "‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ", "‡∏•‡∏≥‡∏õ‡∏≤‡∏á", "‡∏•‡∏≥‡∏û‡∏π‡∏ô", "‡πÄ‡∏•‡∏¢", "‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©", "‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£", "‡∏™‡∏á‡∏Ç‡∏•‡∏≤", "‡∏™‡∏ï‡∏π‡∏•", "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£",
            "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°", "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£", "‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß", "‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ", "‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ", "‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢", "‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ", "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ",
            "‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå", "‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢", "‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π", "‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á", "‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç", "‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ","‡∏≠‡∏∏‡∏î‡∏£", "‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå",
            "‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ", "‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ"
        ]

        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏ô location (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø)
        if location:
            for province in provinces:
                if province in location:
                    self.log(f"‚è≠Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡∏≠‡∏µ‡πÄ‡∏ß‡πâ‡∏ô‡∏ó‡πå '{title}' ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î: {province}")
                    return  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏≠‡∏µ‡πÄ‡∏ß‡πâ‡∏ô‡∏ó‡πå‡∏ô‡∏µ‡πâ
                
        status = determine_status(start_date, end_date)
        if status not in ["upcoming", "ongoing"]:
            self.past_event_count += 1
            if self.past_event_count > 30:
                self.log("üõë ‡πÄ‡∏à‡∏≠ past event ‡πÄ‡∏Å‡∏¥‡∏ô 30 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‚Äî ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
                raise scrapy.exceptions.CloseSpider("Too many past events")
            return

        # ‚úÖ ‡∏î‡∏∂‡∏á URL (Facebook ‡∏Å‡πà‡∏≠‡∏ô, ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Website)
        facebook_url = response.xpath("//span[@style='color: #339966;']//a[contains(@href, 'facebook.com')]/@href").get()
        if not facebook_url:
            facebook_url = response.xpath("//a[contains(@href, 'facebook.com')][not(contains(@href, 'allthaievent'))]/@href").get()
            
        website_url = response.xpath("//span[@style='color: #339966;']//a[contains(@href, 'http')][not(contains(@href, 'facebook.com'))]/@href").get()
        event_url = facebook_url if facebook_url else website_url if website_url else "N/A"

        # ‚úÖ ‡∏î‡∏∂‡∏á Cover Picture
        cover_picture = response.css("a#evimg::attr(href)").get()

        # ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏±‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤
        ticket, ticket_price = self.extract_ticket_info(description)

        # ‚úÖ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
        predicted_categories = predict_category(title, description)

        reliability_score = 2
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        event_data = {
            "title": title,
            "description": description if description else "No description",
            "categories": predicted_categories,
            "start_date": start_date,
            "end_date": end_date,
            "event_slot_time": event_slot_time,
            "location": location,
            "url": event_url,
            "cover_picture": cover_picture,
            "ticket": ticket,
            "ticket_price": ticket_price,
            "reliability_score": reliability_score,
            "timestamp": timestamp,
            "status": determine_status(start_date, end_date)
        }

        # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå JSON
        filename = re.sub(r"[\\/:*?\"<>|]", "_", title) + ".json"

        # ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ã‡∏ü‡πÑ‡∏ü‡∏•‡πå
        base_dir = os.path.dirname(os.path.abspath(__file__))
        raw_data_dir = os.path.join(base_dir, "raw_data", "upcoming")
        os.makedirs(raw_data_dir, exist_ok=True)

        filepath = os.path.join(raw_data_dir, filename)

        # ‚úÖ ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(event_data, f, ensure_ascii=False, indent=4)

        yield event_data


    def extract_description(self, response):
        """ ‡∏î‡∏∂‡∏á #text ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å <div class="separated-border"> ‡∏Å‡πà‡∏≠‡∏ô‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏µ‡∏™‡πâ‡∏° """
        description_text = []
        elements = response.css("div.separated-border *::text").getall()

        for text in elements:
            text = text.strip()
            if not text:
                continue

            # ‡∏´‡∏¢‡∏∏‡∏î‡∏î‡∏∂‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏µ‡∏™‡πâ‡∏° (‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà, ‡πÄ‡∏ß‡∏•‡∏≤, ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà)
            if "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà :" in text or "‡πÄ‡∏ß‡∏•‡∏≤ :" in text or "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà :" in text:
                break

            description_text.append(text)

        return " ".join(description_text).strip()

    def extract_event_details(self, date_info):
        start_date, end_date = None, None
        event_slot_time, location = None, None


        if date_info:
            details_text = " ".join(date_info)

            # ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
            extracted_start, extracted_end = self.extract_dates(details_text)
            if extracted_start != "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏":
                start_date, end_date = extracted_start, extracted_end

            # ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏•‡∏≤: ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏≤‡∏Å "‡πÄ‡∏ß‡∏•‡∏≤ : ..." ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
            for line in date_info:
                if "‡πÄ‡∏ß‡∏•‡∏≤" in line:
                    time_match = re.search(r"‡πÄ‡∏ß‡∏•‡∏≤\s*:\s*(.+)", line)
                    if time_match:
                        event_slot_time = time_match.group(1).strip()
                        event_slot_time = re.sub(r"\s*-\s*", "-", event_slot_time)  # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏≠‡∏ö "-"
                        event_slot_time = re.sub(r"\s*‡∏ô\.*", "", event_slot_time)  # ‡∏•‡∏ö "‡∏ô." ‡∏´‡∏£‡∏∑‡∏≠ "‡∏ô"
                        break

            # ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà
            for line in date_info:
                if "‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà" in line:
                    location_match = re.search(r"‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà\s*:\s*(.+)", line)
                    if location_match:
                        location = location_match.group(1).strip()
                        break

        return start_date, end_date, event_slot_time, location

    def extract_dates(self, text):
        """ ‡∏î‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏µ ‡∏û.‡∏®. ‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®. """
        months = {
            "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°": 1, "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå": 2, "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°": 3, "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô": 4, "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°": 5, "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô": 6,
            "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°": 7, "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°": 8, "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô": 9, "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°": 10, "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô": 11, "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°": 12
        }

        today = datetime.datetime.today()
        thai_today_date = f"{today.day} {list(months.keys())[today.month - 1]} {today.year}"

        patterns = [
            (r"(\d{1,2})\s*-\s*(\d{1,2})\s*(‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°)\s*(\d{4})", 2),
            (r"(?:‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà(?:‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà)?\s*)?(\d{1,2}|‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ)\s*(‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°)?(?:\s*(\d{4}))?\s*(?:‡∏à‡∏ô‡∏ñ‡∏∂‡∏á|‡∏ñ‡∏∂‡∏á|-)\s*(?:‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà\s*)?(\d{1,2})\s*(‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°)(?:\s*(\d{4}))?", 1),
            (r"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà\s*(\d{1,2})\s*(‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°)\s*(\d{4})", 3)
        ]

        for pattern, group_count in patterns:
            match = re.search(pattern, text)
            if match:
                groups = match.groups()

                if group_count == 2:
                    start_day, end_day, month, year = groups
                    year = int(year) - 543
                    return f"{int(start_day)} {month} {year}", f"{int(end_day)} {month} {year}"

                elif group_count == 1:
                    start_day, start_month, start_year, end_day, end_month, end_year = groups

                    if start_day == "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ":
                        start_date_text = thai_today_date
                    else:
                        start_year = int(start_year) - 543 if start_year else None
                        end_year = int(end_year) - 543 if end_year else start_year

                        if start_day and start_month and start_year:
                            start_date_text = f"{int(start_day)} {start_month} {start_year}"
                        else:
                            start_date_text = None

                    if end_day and end_month and end_year:
                        end_date_text = f"{int(end_day)} {end_month} {end_year}"
                    else:
                        end_date_text = None

                    return start_date_text, end_date_text

                elif group_count == 3:
                    day, month, year = groups
                    year = int(year) - 543
                    return f"{int(day)} {month} {year}", None

        return None, None


    def extract_ticket_info(self, description_text):
        ticket_keywords = ["‡∏ö‡∏±‡∏ï‡∏£", "ticket"]
        price_keywords = [
            "‡∏ö‡∏±‡∏ï‡∏£‡∏£‡∏≤‡∏Ñ‡∏≤", "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡∏±‡∏ï‡∏£", "‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°", "ticket price", "price",
            "entry fee", "admission", "entry ticket", "ticket fee"
        ]
        free_keywords = [
            "‡∏ü‡∏£‡∏µ", "free", "‡∏ö‡∏±‡∏ï‡∏£‡∏ü‡∏£‡∏µ", "‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏£‡∏µ", "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢",
            "no charge", "free entry", "free admission"
        ]
        exclude_keywords = ["‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°", "service charge", "‡∏Ñ‡πà‡∏≤‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£", "surcharge"]
        skip_prices = {"67", "68", "23", "24", "25", "100"}

        clean_text = html.unescape(description_text)
        full_text = clean_text.lower()
        paragraphs = re.split(r"[.\n\r]", clean_text)

        ticket = "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°"
        raw_prices = []

        if any(free in full_text for free in free_keywords):
            return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°", None

        if any(keyword in full_text for keyword in ticket_keywords):
            ticket = "‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°"

        for p in paragraphs:
            p_clean = re.sub(r"<.*?>", "", p)
            lower_p = p_clean.lower()

            if any(ex_kw in lower_p for ex_kw in exclude_keywords):
                continue

            if any(price_kw in lower_p for price_kw in price_keywords) or "‡∏ö‡∏≤‡∏ó" in lower_p:
                matches = re.findall(r"\d{1,3}(?:,\d{3})+|\d{3,5}", lower_p)
                for m in matches:
                    try:
                        price = int(m.replace(",", ""))
                        if str(price) in skip_prices or re.match(r"^(25|20)\d{2}$", str(price)):
                            continue
                        if price >= 32:
                            raw_prices.append(price)
                    except:
                        continue

        filtered_prices = raw_prices
        if len(raw_prices) >= 2:
            max_price = max(raw_prices)
            threshold = max_price * 0.3
            filtered_prices = [p for p in raw_prices if p >= threshold]

        if ticket == "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°" and filtered_prices:
            ticket = "‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°"

        return ticket, sorted(filtered_prices) if filtered_prices else None

    
def determine_status(start_date, end_date):
    today = datetime.date.today()
    start = dateparser.parse(start_date, languages=["th", "en"])
    end = dateparser.parse(end_date, languages=["th", "en"])

    if not start or not end:
        return "unknown"

    if today < start.date():
        return "upcoming"
    elif start.date() <= today <= end.date():
        return "ongoing"
    else:
        return "past"

