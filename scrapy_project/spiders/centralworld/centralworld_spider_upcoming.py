import scrapy
import re
import json
import os
import datetime
from scrapy_project.category.predictor import predict_category
import dateparser
import html

class CentralWorldSpider(scrapy.Spider):
    name = "centralworld_spider_upcoming"
    allowed_domains = ["centralworld.co.th"]
    start_urls = [f"https://www.centralworld.co.th/th/events?page={i}" for i in range(1, 11)]  # ‡∏î‡∏∂‡∏á 10 ‡∏´‡∏ô‡πâ‡∏≤

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.past_event_count = 0  # ‚úÖ ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô past event

    def parse(self, response):
        """ ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏≠‡∏µ‡πÄ‡∏ß‡∏ô‡∏ï‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á CentralWorld """
        event_links = response.css("div.card-deck a.card--news::attr(href)").getall()
        full_links = [response.urljoin(link) for link in event_links]

        # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ô‡∏¥‡∏ó‡∏£‡∏£‡∏®‡∏Å‡∏≤‡∏£
        for link in full_links:
            yield scrapy.Request(url=link, callback=self.parse_event)

    def parse_event(self, response):
        title = response.css("h1.news-detail__title::text").get(default="null").strip()
        description = self.extract_description(response)

        # ‡∏î‡∏∂‡∏á‡∏õ‡∏µ‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏û‡∏™‡∏ï‡πå ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏µ‡πÄ‡∏ß‡∏ô‡∏ï‡πå
        post_date_text = response.css("div.news-detail__date::text").get()
        post_year = re.search(r"(\d{4})", post_date_text) if post_date_text else None
        post_year = post_year.group(1) if post_year else str(datetime.now().year)

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å description
        start_date, end_date = self.extract_dates(description, response)

        event_slot_time = "10:00‚Äì22:00"

        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î location
        location = "Central World"

        # URL ‡∏Ç‡∏≠‡∏á‡∏≠‡∏µ‡πÄ‡∏ß‡∏ô‡∏ï‡πå
        event_urls = "/".join(response.url.split("/")[:6])

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏±‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤
        ticket, ticket_price = self.extract_ticket_info(description)

        predicted_categories = predict_category(title, description)

        # ‡∏î‡∏∂‡∏á Cover Picture
        cover_picture = response.css("div.col-lg-8.col-xxl-6 figure img::attr(src)").get()

        if not cover_picture:  
            cover_picture = response.css("div.col-lg-8.col-xxl-6 p.text-center img::attr(src)").get()

        cover_picture = f"https://www.centralworld.co.th{cover_picture}" if cover_picture else "null"
        
        reliability_score = 5
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        status = determine_status(start_date, end_date)
        if status not in ["upcoming", "ongoing"]:
            self.past_event_count += 1
            if self.past_event_count > 100:
                self.log("üõë ‡πÄ‡∏à‡∏≠ past event ‡πÄ‡∏Å‡∏¥‡∏ô 30 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‚Äî ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
                raise scrapy.exceptions.CloseSpider("Too many past events")
            return

        event_data = {
            "title": title if title else "null",
            "description": description if description else "null",
            "categories": predicted_categories,
            "start_date": start_date,
            "end_date": end_date,
            "event_slot_time": event_slot_time,
            "location": location,
            "url": event_urls,
            "ticket": ticket,
            "ticket_price": ticket_price,
            "cover_picture": cover_picture,
            "reliability_score": reliability_score,
            "timestamp": timestamp,
            "status": determine_status(start_date, end_date)

        }

        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô JSON
        filename = re.sub(r"[\\/:*?\"<>|]", "_", title) + ".json"

        # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á spider ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡πà‡∏≠‡∏î‡πâ‡∏ß‡∏¢ raw_data
        base_dir = os.path.dirname(os.path.abspath(__file__))
        raw_data_dir = os.path.join(base_dir, "raw_data", "upcoming")
        os.makedirs(raw_data_dir, exist_ok=True)  # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ

        filepath = os.path.join(raw_data_dir, filename)

        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(event_data, f, ensure_ascii=False, indent=4)

        yield event_data


    def extract_description(self, response):
        """ ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡∏≠‡∏µ‡πÄ‡∏ß‡∏ô‡∏ï‡πå‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ HTML tag ‡πÉ‡∏î ‡πÜ """
        texts = response.css("div.col-lg-8.col-xxl-6 ::text").getall()
        description = " ".join([t.strip() for t in texts if t.strip()])
        return description if description else "null"


    def extract_dates(self, text, response):
        months = {
            "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°": "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°", "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå": "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå", "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°": "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°", "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô": "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô",
            "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°": "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°", "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô": "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô", "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°": "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°", "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°": "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°",
            "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô": "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô", "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°": "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°", "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô": "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô", "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°": "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°",
            "‡∏°.‡∏Ñ.": "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°", "‡∏Å.‡∏û.": "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå", "‡∏°‡∏µ.‡∏Ñ.": "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°", "‡πÄ‡∏°.‡∏¢.": "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô",
            "‡∏û.‡∏Ñ.": "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°", "‡∏°‡∏¥.‡∏¢.": "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô", "‡∏Å.‡∏Ñ.": "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°", "‡∏™.‡∏Ñ.": "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°",
            "‡∏Å.‡∏¢.": "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô", "‡∏ï.‡∏Ñ.": "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°", "‡∏û.‡∏¢.": "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô", "‡∏ò.‡∏Ñ.": "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°",
            "Jan": "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°", "Feb": "‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå", "Mar": "‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°", "Apr": "‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô",
            "May": "‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°", "Jun": "‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô", "Jul": "‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°", "Aug": "‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°",
            "Sep": "‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô", "Oct": "‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°", "Nov": "‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô", "Dec": "‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°"
        }
        
        post_date_text = response.css("div.news-detail__date::text").get()
        post_year_match = re.search(r"(\d{4})", post_date_text) if post_date_text else None
        post_year = int(post_year_match.group(1)) if post_year_match else datetime.now().year

        # ‡πÅ‡∏õ‡∏•‡∏á ‡∏û.‡∏®. ‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®. ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        if post_year > 2500:
            post_year -= 543

        # **‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: mixed_pattern ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô!**
        mixed_pattern = r"(\d{1,2})\s*(‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°|‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏°.‡∏Ñ.|‡∏Å.‡∏û.|‡∏°‡∏µ.‡∏Ñ.|‡πÄ‡∏°.‡∏¢.|‡∏û.‡∏Ñ.|‡∏°‡∏¥.‡∏¢.|‡∏Å.‡∏Ñ.|‡∏™.‡∏Ñ.|‡∏Å.‡∏¢.|‡∏ï.‡∏Ñ.|‡∏û.‡∏¢.|‡∏ò.‡∏Ñ.)\s*-\s*(\d{1,2})\s*(‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°|‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏°.‡∏Ñ.|‡∏Å.‡∏û.|‡∏°‡∏µ.‡∏Ñ.|‡πÄ‡∏°.‡∏¢.|‡∏û.‡∏Ñ.|‡∏°‡∏¥.‡∏¢.|‡∏Å.‡∏Ñ.|‡∏™.‡∏Ñ.|‡∏Å.‡∏¢.|‡∏ï.‡∏Ñ.|‡∏û.‡∏¢.|‡∏ò.‡∏Ñ.)\s*(\d{4})"
        full_pattern = r"(\d{1,2})\s*(‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°|‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°)\s*(\d{4})?\s*-\s*(\d{1,2})\s*(‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°|‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°)\s*(\d{4})?"
        short_pattern = r"(\d{1,2})-(\d{1,2})\s*(‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°|‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏°.‡∏Ñ.|‡∏Å.‡∏û.|‡∏°‡∏µ.‡∏Ñ.|‡πÄ‡∏°.‡∏¢.|‡∏û.‡∏Ñ.|‡∏°‡∏¥.‡∏¢.|‡∏Å.‡∏Ñ.|‡∏™.‡∏Ñ.|‡∏Å.‡∏¢.|‡∏ï.‡∏Ñ.|‡∏û.‡∏¢.|‡∏ò.‡∏Ñ.)"
        single_with_year_pattern = r"(\d{1,2})\s*(‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°|‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏°.‡∏Ñ.|‡∏Å.‡∏û.|‡∏°‡∏µ.‡∏Ñ.|‡πÄ‡∏°.‡∏¢.|‡∏û.‡∏Ñ.|‡∏°‡∏¥.‡∏¢.|‡∏Å.‡∏Ñ.|‡∏™.‡∏Ñ.|‡∏Å.‡∏¢.|‡∏ï.‡∏Ñ.|‡∏û.‡∏¢.|‡∏ò.‡∏Ñ.)\s*(\d{2,4})"
        single_pattern = r"^(\d{1,2})\s*(‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°|‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏°.‡∏Ñ.|‡∏Å.‡∏û.|‡∏°‡∏µ.‡∏Ñ.|‡πÄ‡∏°.‡∏¢.|‡∏û.‡∏Ñ.|‡∏°‡∏¥.‡∏¢.|‡∏Å.‡∏Ñ.|‡∏™.‡∏Ñ.|‡∏Å.‡∏¢.|‡∏ï.‡∏Ñ.|‡∏û.‡∏¢.|‡∏ò.‡∏Ñ.)$"
        this_year_pattern = r"(\d{1,2})\s*-\s*(\d{1,2})\s*(‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°|‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°)‡∏ô‡∏µ‡πâ"
        new_this_year_pattern = r"(\d{1,2})\s*(‡∏°.‡∏Ñ.|‡∏Å.‡∏û.|‡∏°‡∏µ.‡∏Ñ.|‡πÄ‡∏°.‡∏¢.|‡∏û.‡∏Ñ.|‡∏°‡∏¥.‡∏¢.|‡∏Å.‡∏Ñ.|‡∏™.‡∏Ñ.|‡∏Å.‡∏¢.|‡∏ï.‡∏Ñ.|‡∏û.‡∏¢.|‡∏ò.‡∏Ñ.)\s*‡∏ô‡∏µ‡πâ"
        range_this_year_pattern = r"(\d{1,2})\s*-\s*(\d{1,2})\s*(‡∏°.‡∏Ñ.|‡∏Å.‡∏û.|‡∏°‡∏µ.‡∏Ñ.|‡πÄ‡∏°.‡∏¢.|‡∏û.‡∏Ñ.|‡∏°‡∏¥.‡∏¢.|‡∏Å.‡∏Ñ.|‡∏™.‡∏Ñ.|‡∏Å.‡∏¢.|‡∏ï.‡∏Ñ.|‡∏û.‡∏¢.|‡∏ò.‡∏Ñ.)\s*‡∏ô‡∏µ‡πâ"
        single_this_year_pattern = r"(\d{1,2})\s*(‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°|‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°)‡∏ô‡∏µ‡πâ"
        eng_date_pattern = r"(\d{1,2})\s*([A-Za-z]{3})\s*(\d{4})"
        eng_range_pattern = r"(\d{1,2})\s*-\s*(\d{1,2})\s*([A-Za-z]{3})\s*(\d{4})"
        
        match_mixed = re.search(mixed_pattern, text)
        match_full = re.search(full_pattern, text)
        match_short = re.search(short_pattern, text)
        match_single_with_year = re.search(single_with_year_pattern, text)
        match_single = re.search(single_pattern, text)
        match_this_year = re.search(this_year_pattern, text)
        match_new_this_year = re.search(new_this_year_pattern, text)
        match_range_this_year = re.search(range_this_year_pattern, text)
        match_single_this_year = re.search(single_this_year_pattern, text)
        match_eng_range = re.search(eng_range_pattern, text)
        match_eng_date = re.search(eng_date_pattern, text)
        
        if match_mixed:
            start_day, start_month, end_day, end_month, end_year = match_mixed.groups()
            end_year = int(end_year) - 543  
            start_year = end_year  
            return f"{int(start_day)} {months[start_month]} {start_year}", f"{int(end_day)} {months[end_month]} {end_year}"
        elif match_full:
            start_day, start_month, start_year, end_day, end_month, end_year = match_full.groups()
            start_year = int(start_year) - 543 if start_year else post_year
            end_year = int(end_year) - 543 if end_year else start_year
            return f"{int(start_day)} {months[start_month]} {start_year}", f"{int(end_day)} {months[end_month]} {end_year}"
        elif match_short:
            start_day, end_day, month = match_short.groups()
            return f"{int(start_day)} {months[month]} {post_year}", f"{int(end_day)} {months[month]} {post_year}"
        elif match_single_with_year:
            day, month, year = match_single_with_year.groups()
            year = int(year)
            if year < 100:
                year = (year + 2500) - 543  
            elif year > 2500:
                year = year - 543
            return f"{int(day)} {months[month]} {year}", f"{int(day)} {months[month]} {year}"
        elif match_single:
            day, month = match_single.groups()
            return f"{int(day)} {months[month]} {post_year}", f"{int(day)} {months[month]} {post_year}"
        elif match_this_year:
            start_day, end_day, month = match_this_year.groups()
            return f"{int(start_day)} {months[month]} {post_year}", f"{int(end_day)} {months[month]} {post_year}" 
        elif match_new_this_year:
            day, month = match_new_this_year.groups()
            return f"{int(day)} {months[month]} {post_year}", f"{int(day)} {months[month]} {post_year}"
        elif match_range_this_year:
            start_day, end_day, month = match_range_this_year.groups()
            return f"{int(start_day)} {months[month]} {post_year}", f"{int(end_day)} {months[month]} {post_year}"
        elif match_single_this_year:
            day, month = match_single_this_year.groups()
            return f"{int(day)} {months[month]} {post_year}", f"{int(day)} {months[month]} {post_year}"
        elif match_eng_range:
            start_day, end_day, month, year = match_eng_range.groups()
            month = month.capitalize()  # Normalize ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Apr, May, Jun
            year = int(year)
            return f"{int(start_day)} {months[month]} {year}", f"{int(end_day)} {months[month]} {year}"
        elif match_eng_date:
            day, month, year = match_eng_date.groups()
            month = month.capitalize()
            year = int(year)
            return f"{int(day)} {months[month]} {year}", f"{int(day)} {months[month]} {year}"


        return "null", "null"

    def extract_ticket_info(self, description_text):
        ticket_keywords = ["‡∏ö‡∏±‡∏ï‡∏£", "ticket"]
        price_keywords = [
            "‡∏ö‡∏±‡∏ï‡∏£‡∏£‡∏≤‡∏Ñ‡∏≤", "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡∏±‡∏ï‡∏£", "‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°", "ticket price", "price",
            "entry fee", "admission", "entry ticket", "ticket fee"
        ]
        free_keywords = [
            "‡∏ü‡∏£‡∏µ", "free", "‡∏ö‡∏±‡∏ï‡∏£‡∏ü‡∏£‡∏µ", "‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏£‡∏µ", "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢",
            "no charge", "free entry", "free admission"
        ]
        exclude_keywords = ["‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°", "service charge", "‡∏Ñ‡πà‡∏≤‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£", "surcharge"]
        skip_prices = {"67", "68", "23", "24", "25", "100"}

        clean_text = html.unescape(description_text)
        full_text = clean_text.lower()
        paragraphs = re.split(r"[.\n\r]", clean_text)

        ticket = "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°"
        raw_prices = []

        if any(free in full_text for free in free_keywords):
            return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°", None

        if any(keyword in full_text for keyword in ticket_keywords):
            ticket = "‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°"

        for p in paragraphs:
            p_clean = re.sub(r"<.*?>", "", p)
            lower_p = p_clean.lower()

            if any(ex_kw in lower_p for ex_kw in exclude_keywords):
                continue

            if any(price_kw in lower_p for price_kw in price_keywords) or "‡∏ö‡∏≤‡∏ó" in lower_p:
                matches = re.findall(r"\d{1,3}(?:,\d{3})+|\d{3,5}", lower_p)
                for m in matches:
                    try:
                        price = int(m.replace(",", ""))
                        if str(price) in skip_prices or re.match(r"^(25|20)\d{2}$", str(price)):
                            continue
                        if price >= 32:
                            raw_prices.append(price)
                    except:
                        continue

        filtered_prices = raw_prices
        if len(raw_prices) >= 2:
            max_price = max(raw_prices)
            threshold = max_price * 0.3
            filtered_prices = [p for p in raw_prices if p >= threshold]

        if ticket == "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°" and filtered_prices:
            ticket = "‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°"

        return ticket, sorted(filtered_prices) if filtered_prices else None
    
def determine_status(start_date, end_date):
    today = datetime.date.today()
    start = dateparser.parse(start_date, languages=["th", "en"])
    end = dateparser.parse(end_date, languages=["th", "en"])

    if not start or not end:
        return "unknown"

    if today < start.date():
        return "upcoming"
    elif start.date() <= today <= end.date():
        return "ongoing"
    else:
        return "past"

